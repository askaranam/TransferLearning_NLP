{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ULMFiT.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/askaranam/TransferLearning_NLP/blob/master/ULMFiT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RgvhqyAnN2g4",
        "colab_type": "text"
      },
      "source": [
        "A jupyter notebook created in Google Colab for experimenting with transfer learning for text classification using \n",
        "AWD_LSTM and Transformer architectures using fastai library in python\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAa4mRjJBj3c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Installing Pytorch and fast ai\n",
        "!pip install torch_nightly -f https://download.pytorch.org/whl/nightly/cu92/torch_nightly.html\n",
        "# installing FastAi (latest version)\n",
        "!pip install fastai"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ltvbM6fN3mv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import fastai\n",
        "from fastai import *\n",
        "from fastai.text import * \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from functools import partial\n",
        "import io\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8t049zE4CE_W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# importing dataset from sklearn datasets\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "dataset = fetch_20newsgroups(shuffle=True, random_state=1, remove=('headers', 'footers', 'quotes'))\n",
        "documents = dataset.data\n",
        "df = pd.DataFrame({'label':dataset.target, 'text':dataset.data})\n",
        "df.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmBUiJJHCaWK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Using data from two classes (specifically, classes: 1, 10) for the purpose of binary classification\n",
        "df = df[df['label'].isin([1,10])]\n",
        "df = df.reset_index(drop = True)\n",
        "df['label'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Raey2YIZCnts",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords \n",
        "stop_words = stopwords.words('english')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6imO8O0DwJE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# removing unwanted characters\n",
        "df['text'] = df['text'].str.replace(\"[^a-zA-Z]\", \" \")\n",
        "\n",
        "# tokenization \n",
        "tokenized_doc = df['text'].apply(lambda x: x.split())\n",
        "\n",
        "# remove stop-words \n",
        "tokenized_doc = tokenized_doc.apply(lambda x: [item for item in x if item not in stop_words])\n",
        "\n",
        "# de-tokenization \n",
        "detokenized_doc = [] \n",
        "for i in range(len(df)): \n",
        "    t = ' '.join(tokenized_doc[i]) \n",
        "    detokenized_doc.append(t) \n",
        "\n",
        "df['text'] = detokenized_doc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3dq1sMTD7Go",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# split data into training and validation set\n",
        "df_trn, df_val = train_test_split(df, stratify = df['label'], test_size = 0.4, random_state = 12)\n",
        "df_trn.shape, df_val.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTt3nZfkEAeX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Language model data\n",
        "data_lm = TextLMDataBunch.from_df(train_df = df_trn, valid_df = df_val, path = \"\")\n",
        "\n",
        "# Classifier model data\n",
        "data_clas = TextClasDataBunch.from_df(path = \"\", train_df = df_trn, valid_df = df_val, vocab=data_lm.train_ds.vocab, bs=32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-43nxfZEFhC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Pretrained weights for each architecture, it could be AWD_LSTM or Transformer\n",
        "learn = language_model_learner(data_lm, AWD_LSTM , drop_mult=0.7)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opz4C_cnEPCL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Using One Cycle Policy for regularization \n",
        "# from https://arxiv.org/abs/1803.09820\n",
        "learn.fit_one_cycle(2, 1e-12)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzEdG0b8FwS2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save the encoder\n",
        "learn.save_encoder('ft_enc')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lgMh9-BGIAp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# now use Classification model to build the classifier with fine tuned encoder \n",
        "learn = text_classifier_learner(data_clas, drop_mult=0.7, arch = AWD_LSTM)\n",
        "learn.load_encoder('ft_enc')\n",
        "learn.fit_one_cycle(1, 1e-2)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4RSp4jpH24Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "51641886-53a8-47b4-e303-c75e8ab791c5"
      },
      "source": [
        "# get predictions\n",
        "preds, targets = learn.get_preds()\n",
        "\n",
        "predictions = np.argmax(preds, axis = 1)\n",
        "pd.crosstab(predictions, targets)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>col_0</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>row_0</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>215</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>19</td>\n",
              "      <td>217</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "col_0    0    1\n",
              "row_0          \n",
              "0      215   23\n",
              "1       19  217"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGads09VNigt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}